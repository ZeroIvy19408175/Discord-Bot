import discord
from discord.ext import commands, tasks
import os
import logging
import json
import uuid
import base64
from datetime import datetime, timezone
import httpx
import google.generativeai as genai
import google.ai.generativelanguage as glm

# config.pyì—ì„œ ëª¨ë“  ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from config import (
    DISCORD_BOT_TOKEN, MEMORY_API_URL, GEMINI_API_KEY,
    SYSTEM_INSTRUCTION, OPENWEATHER_API, SERPAPI_API_KEY
)
# utils.pyì—ì„œ ì‹¤ì œ ì‹¤í–‰í•  í•¨ìˆ˜ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from utils import get_uptime, get_weather, search_web

# ----- ê¸°ë³¸ ì„¤ì • -----
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
intents = discord.Intents.all()
bot = commands.Bot(command_prefix='ì œ', intents=intents)
start_time = datetime.now(timezone.utc)

# ----- Tools (í•¨ìˆ˜) ì •ì˜ -----
tools = [
    glm.Tool(function_declarations=[
        glm.FunctionDeclaration(
            name="get_weather",
            description="íŠ¹ì • ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.",
            parameters=glm.Schema(type=glm.Type.OBJECT, properties={
                "city": glm.Schema(type=glm.Type.STRING, description="ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ë„ì‹œ ì´ë¦„ (ì˜ì–´ë¡œ)")}, required=["city"]),
        ),
        glm.FunctionDeclaration(
            name="get_uptime",
            description="ë´‡ì˜ í˜„ì¬ ê°€ë™ ì‹œê°„ì„ ì•Œë ¤ì¤ë‹ˆë‹¤.",
        ),
        glm.FunctionDeclaration(
            name="search_web",
            description="ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
            parameters=glm.Schema(type=glm.Type.OBJECT,
                                  properties={"query": glm.Schema(type=glm.Type.STRING, description="ê²€ìƒ‰í•  ë‚´ìš©")},
                                  required=["query"]),
        ),
    ])
]
available_functions = {
    "get_weather": get_weather,
    "get_uptime": get_uptime,
    "search_web": search_web,
}

# ----- Google Gemini API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • -----
generation_model = None
try:
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        generation_model = genai.GenerativeModel(
            'gemini-flash-latest',
            system_instruction=SYSTEM_INSTRUCTION,
            tools=tools
        )
        logging.info("Gemini API í´ë¼ì´ì–¸íŠ¸ê°€ í˜ë¥´ì†Œë‚˜ ë° ëª¨ë“  ë„êµ¬ì™€ í•¨ê»˜ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        logging.warning("ê²½ê³ : config.pyì— GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
except Exception as e:
    logging.error(f"Gemini API ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ----- ë¹„íœ˜ë°œì„± ë‹¨ê¸°ê¸°ì–µ ê´€ë¦¬ -----
MEMORY_FILE_PATH = "bot_short_term_memory.json"
user_chat_histories = {}  # ìœ ì €ë³„ ëŒ€í™” ê¸°ë¡ (ì´ë¯¸ì§€ í¬í•¨ ë‹¨ê¸°ê¸°ì–µ)


def save_memory_to_disk():
    """í˜„ì¬ ë‹¨ê¸°ê¸°ì–µ(ëŒ€í™” ê¸°ë¡)ì„ JSON íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(MEMORY_FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(user_chat_histories, f, ensure_ascii=False, indent=4)
        logging.info(f"ë‹¨ê¸° ê¸°ì–µì„ '{MEMORY_FILE_PATH}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logging.error(f"ë‹¨ê¸° ê¸°ì–µ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")


def load_memory_from_disk():
    """JSON íŒŒì¼ì—ì„œ ë‹¨ê¸°ê¸°ì–µ(ëŒ€í™” ê¸°ë¡)ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    global user_chat_histories
    try:
        if os.path.exists(MEMORY_FILE_PATH):
            with open(MEMORY_FILE_PATH, "r", encoding="utf-8") as f:
                user_chat_histories = json.load(f)
            logging.info(f"'{MEMORY_FILE_PATH}'ì—ì„œ ë‹¨ê¸° ê¸°ì–µì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logging.error(f"ë‹¨ê¸° ê¸°ì–µ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")


@tasks.loop(minutes=5)
async def periodic_save_task():
    save_memory_to_disk()


# ----- Discord ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ -----

@bot.event
async def on_ready():
    load_memory_from_disk()
    periodic_save_task.start()
    logging.info(f'{bot.user.name} ì˜¨ë¼ì¸! ëª¨ë“  ê¸°ì–µì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.')


@bot.event
async def on_close():
    logging.info("ë´‡ì´ ì¢…ë£Œë©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ê¸°ì–µì„ ì €ì¥í•©ë‹ˆë‹¤...")
    save_memory_to_disk()


@bot.event
async def on_message(message):
    if message.author == bot.user or message.author.bot: return
    if not message.content.strip() and not message.attachments: return
    if not message.content.startswith(bot.command_prefix):
        await process_chat_message(message)
    await bot.process_commands(message)


# ----- í•µì‹¬ ëŒ€í™” ì²˜ë¦¬ ë¡œì§ -----

async def process_chat_message(message):
    user_name = message.author.name
    message_memo = str(uuid.uuid4())
    user_message_record = {"role": "user", "content": message.content, "memo": message_memo}

    if message.attachments:
        for attachment in message.attachments:
            if attachment.content_type and attachment.content_type.startswith("image/"):
                try:
                    image_bytes = await attachment.read()
                    user_message_record["image_base64"] = base64.b64encode(image_bytes).decode("utf-8")
                    user_message_record["mime_type"] = attachment.content_type
                    logging.info(f"ì´ë¯¸ì§€ ì²¨ë¶€íŒŒì¼ì„ ë‹¨ê¸° ê¸°ì–µì— ì €ì¥: {attachment.filename}")
                    break
                except Exception as e:
                    await message.channel.send("ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆì–´.");
                    return

    if user_name not in user_chat_histories: user_chat_histories[user_name] = []
    user_chat_histories[user_name].append(user_message_record)

    text_only_history = [{"role": msg["role"], "content": msg["content"], "memo": msg.get("memo")} for msg in
                         user_chat_histories[user_name]]
    payload = {
        "messages": text_only_history, "memory_type": "hypa", "max_context_tokens": 8192,
        "character_name": bot.user.name, "room_data": {}
    }

    async with message.channel.typing():
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(MEMORY_API_URL, json=payload)
                response.raise_for_status()
            memory_response = response.json()
            processed_text_messages = memory_response["processed_messages"]

            final_gemini_messages = []
            for processed_msg in processed_text_messages:
                memo, gemini_parts = processed_msg.get("memo"), []
                if processed_msg.get("content"): gemini_parts.append(glm.Part(text=processed_msg["content"]))
                if memo:
                    for original_msg in user_chat_histories[user_name]:
                        if original_msg.get("memo") == memo and "image_base64" in original_msg:
                            gemini_parts.append(glm.Part(inline_data=glm.Blob(mime_type=original_msg["mime_type"],
                                                                              data=base64.b64decode(
                                                                                  original_msg["image_base64"]))))
                            break
                if gemini_parts:
                    final_gemini_messages.append(
                        {"role": "model" if processed_msg["role"] == "assistant" else "user", "parts": gemini_parts})

            if not generation_model:
                await message.channel.send("ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì–´.");
                return

            chat_session = generation_model.start_chat(history=final_gemini_messages[:-1])
            final_user_message_for_gemini = final_gemini_messages[-1]['parts'] if final_gemini_messages else []
            if not final_user_message_for_gemini: return
            llm_response = await chat_session.send_message_async(final_user_message_for_gemini)

            if not llm_response.candidates or not llm_response.candidates[0].content.parts:
                logging.info("ëª¨ë¸ì´ ì‘ë‹µí•˜ì§€ ì•Šê¸°ë¡œ ê²°ì •í•˜ì—¬ ì¹¨ë¬µí•©ë‹ˆë‹¤.")
                user_chat_histories[user_name].append({"role": "assistant", "content": "", "memo": str(uuid.uuid4())})
                return

            while True:
                response_part = llm_response.candidates[0].content.parts[0]
                if response_part.function_call:
                    function_call, fname, args = response_part.function_call, response_part.function_call.name, {k: v
                                                                                                                 for
                                                                                                                 k, v in
                                                                                                                 response_part.function_call.args.items()}
                    logging.info(f"í•¨ìˆ˜ í˜¸ì¶œ: {fname}({args})")
                    if fname in available_functions:
                        if fname == "get_weather": args['api_key'] = OPENWEATHER_API
                        f_response = available_functions[fname](**args)
                        llm_response = await chat_session.send_message_async(glm.Part(
                            function_response=glm.FunctionResponse(name=fname, response={"result": f_response})))
                    else:
                        llm_response = await chat_session.send_message_async(glm.Part(
                            function_response=glm.FunctionResponse(name=fname, response={"result": "ì•Œ ìˆ˜ ì—†ëŠ” í•¨ìˆ˜"})))
                else:
                    break

            response_text = llm_response.text.strip()
            if response_text:
                await message.channel.send(response_text)

            user_chat_histories[user_name].append(
                {"role": "assistant", "content": response_text, "memo": str(uuid.uuid4())})

        except httpx.RequestError as e:
            await message.channel.send(f"ë©”ëª¨ë¦¬ ì„œë²„ ì—°ê²° ì‹¤íŒ¨. ğŸ§  (ì—ëŸ¬: {e})")
        except Exception as e:
            await message.channel.send(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ğŸ¤¯ (ì—ëŸ¬: {e})")
            logging.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        finally:
            save_memory_to_disk()


# ----- Discord ì»¤ë§¨ë“œ -----

@bot.command()
async def ì—…íƒ€ì„(ctx):
    await ctx.send(f"ë‚´ê°€ ê¹¨ì–´ë‚œ ì§€: {get_uptime(start_time)}")


@bot.command()
async def ê¸°ì–µì´ˆê¸°í™”(ctx):
    user_name = ctx.author.name
    if user_name in user_chat_histories: del user_chat_histories[user_name]
    save_memory_to_disk()  # ì´ˆê¸°í™”ëœ ìƒíƒœë¥¼ ë°”ë¡œ ì €ì¥
    await ctx.send(f"{user_name}ì™€ì˜ ë‹¨ê¸° ê¸°ì–µì„ ëª¨ë‘ ì§€ì› ì–´. (ì¥ê¸°ê¸°ì–µì€ ë°±ì—”ë“œ ì„œë²„ì—ì„œ ë³„ë„ë¡œ ê´€ë¦¬ë¼!)")


if __name__ == "__main__":
    if not all([DISCORD_BOT_TOKEN, MEMORY_API_URL, GEMINI_API_KEY, SERPAPI_API_KEY]):
        raise ValueError("í•„ìˆ˜ API í‚¤ê°€ config.pyì— ì—†ìŠµë‹ˆë‹¤.")
    try:
        bot.run(DISCORD_BOT_TOKEN)
    except KeyboardInterrupt:
        print("\ní‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ê°ì§€. ì¢…ë£Œ ì „ ê¸°ì–µì„ ì €ì¥í•©ë‹ˆë‹¤...")
        save_memory_to_disk()
    finally:
        print("ë´‡ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")